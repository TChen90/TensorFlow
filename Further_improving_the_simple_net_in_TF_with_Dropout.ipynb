{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Further improving the simple net in TF with Dropout.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMMojReMXFS8wDdhNwOveTz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TChen90/TensorFlow/blob/master/Further_improving_the_simple_net_in_TF_with_Dropout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Bynu3kQxMQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tElq14Xxbsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the MNIST dataset\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rI2mKbpqx4fe",
        "colab_type": "code",
        "outputId": "5415d1ef-caa4-4d63-d591-47c6b6f20677",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# X_train is 60,000 rows of 28*28 values\n",
        "X_train.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDe96dpkx7aN",
        "colab_type": "code",
        "outputId": "b09c616f-ebbb-4ee1-eb07-006efb8731a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# A sample digit\n",
        "digit = X_train[4]\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLy-19ciysur",
        "colab_type": "code",
        "outputId": "12b3bb42-4a99-42cd-9dd0-1b7b8ba5551d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(y_train[4])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zeMX1_4yyvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape\n",
        "X_train = X_train.reshape(60000, 784).astype('float32')\n",
        "X_test = X_test.reshape(10000, 784).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtqPYCJ8zoTb",
        "colab_type": "code",
        "outputId": "83664fa5-9bc7-4d2a-edcc-4208e642855a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Normalize inputs to be within [0, 1]\n",
        "X_train, X_test = X_train/255.0, X_test/255.0\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiR-c2_s03il",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Labes have one-hot representation\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKarMYZm19jg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the model\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(128, activation='relu', input_shape=(784,), name='dense_layer'))\n",
        "model.add(keras.layers.Dropout(0.3))\n",
        "model.add(keras.layers.Dense(128, activation='relu', name='dense_layer2'))\n",
        "model.add(keras.layers.Dropout(0.3))\n",
        "model.add(keras.layers.Dense(10, activation='softmax', name='dense_layer3'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1svss-52pdr",
        "colab_type": "code",
        "outputId": "7a913c43-c35b-4126-a027-11a6409f8c70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "# Summary of the model\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_layer (Dense)          (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_layer2 (Dense)         (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_layer3 (Dense)         (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6t64rOK2skT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling the model\n",
        "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57eHaRKG26aF",
        "colab_type": "code",
        "outputId": "0532cc74-2e0d-400d-e3d4-48b4cc3cf3b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, batch_size=128, epochs=200, verbose=1, validation_split=0.2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.7193 - accuracy: 0.4608 - val_loss: 0.9250 - val_accuracy: 0.8073\n",
            "Epoch 2/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9325 - accuracy: 0.7139 - val_loss: 0.5382 - val_accuracy: 0.8634\n",
            "Epoch 3/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7030 - accuracy: 0.7859 - val_loss: 0.4248 - val_accuracy: 0.8887\n",
            "Epoch 4/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6004 - accuracy: 0.8181 - val_loss: 0.3731 - val_accuracy: 0.8980\n",
            "Epoch 5/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5366 - accuracy: 0.8393 - val_loss: 0.3385 - val_accuracy: 0.9065\n",
            "Epoch 6/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4912 - accuracy: 0.8540 - val_loss: 0.3154 - val_accuracy: 0.9124\n",
            "Epoch 7/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4597 - accuracy: 0.8629 - val_loss: 0.2965 - val_accuracy: 0.9176\n",
            "Epoch 8/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4341 - accuracy: 0.8707 - val_loss: 0.2808 - val_accuracy: 0.9200\n",
            "Epoch 9/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4102 - accuracy: 0.8776 - val_loss: 0.2681 - val_accuracy: 0.9237\n",
            "Epoch 10/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3945 - accuracy: 0.8844 - val_loss: 0.2586 - val_accuracy: 0.9266\n",
            "Epoch 11/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3776 - accuracy: 0.8879 - val_loss: 0.2483 - val_accuracy: 0.9287\n",
            "Epoch 12/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3623 - accuracy: 0.8949 - val_loss: 0.2399 - val_accuracy: 0.9308\n",
            "Epoch 13/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3482 - accuracy: 0.8974 - val_loss: 0.2338 - val_accuracy: 0.9322\n",
            "Epoch 14/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3362 - accuracy: 0.9013 - val_loss: 0.2243 - val_accuracy: 0.9348\n",
            "Epoch 15/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3290 - accuracy: 0.9047 - val_loss: 0.2187 - val_accuracy: 0.9368\n",
            "Epoch 16/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3194 - accuracy: 0.9064 - val_loss: 0.2128 - val_accuracy: 0.9392\n",
            "Epoch 17/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3099 - accuracy: 0.9095 - val_loss: 0.2065 - val_accuracy: 0.9416\n",
            "Epoch 18/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3008 - accuracy: 0.9130 - val_loss: 0.2015 - val_accuracy: 0.9423\n",
            "Epoch 19/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2937 - accuracy: 0.9139 - val_loss: 0.1965 - val_accuracy: 0.9441\n",
            "Epoch 20/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2861 - accuracy: 0.9180 - val_loss: 0.1923 - val_accuracy: 0.9457\n",
            "Epoch 21/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2803 - accuracy: 0.9185 - val_loss: 0.1880 - val_accuracy: 0.9465\n",
            "Epoch 22/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2746 - accuracy: 0.9202 - val_loss: 0.1835 - val_accuracy: 0.9485\n",
            "Epoch 23/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2718 - accuracy: 0.9195 - val_loss: 0.1807 - val_accuracy: 0.9488\n",
            "Epoch 24/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2642 - accuracy: 0.9234 - val_loss: 0.1763 - val_accuracy: 0.9503\n",
            "Epoch 25/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2596 - accuracy: 0.9242 - val_loss: 0.1737 - val_accuracy: 0.9510\n",
            "Epoch 26/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2531 - accuracy: 0.9249 - val_loss: 0.1699 - val_accuracy: 0.9528\n",
            "Epoch 27/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2473 - accuracy: 0.9278 - val_loss: 0.1665 - val_accuracy: 0.9533\n",
            "Epoch 28/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2435 - accuracy: 0.9286 - val_loss: 0.1639 - val_accuracy: 0.9532\n",
            "Epoch 29/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2388 - accuracy: 0.9300 - val_loss: 0.1612 - val_accuracy: 0.9542\n",
            "Epoch 30/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2376 - accuracy: 0.9309 - val_loss: 0.1583 - val_accuracy: 0.9550\n",
            "Epoch 31/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2309 - accuracy: 0.9328 - val_loss: 0.1558 - val_accuracy: 0.9553\n",
            "Epoch 32/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2298 - accuracy: 0.9331 - val_loss: 0.1532 - val_accuracy: 0.9563\n",
            "Epoch 33/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2293 - accuracy: 0.9332 - val_loss: 0.1514 - val_accuracy: 0.9567\n",
            "Epoch 34/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2213 - accuracy: 0.9353 - val_loss: 0.1497 - val_accuracy: 0.9576\n",
            "Epoch 35/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2171 - accuracy: 0.9368 - val_loss: 0.1481 - val_accuracy: 0.9578\n",
            "Epoch 36/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2138 - accuracy: 0.9388 - val_loss: 0.1453 - val_accuracy: 0.9587\n",
            "Epoch 37/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2129 - accuracy: 0.9375 - val_loss: 0.1433 - val_accuracy: 0.9590\n",
            "Epoch 38/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2088 - accuracy: 0.9390 - val_loss: 0.1417 - val_accuracy: 0.9592\n",
            "Epoch 39/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2047 - accuracy: 0.9394 - val_loss: 0.1404 - val_accuracy: 0.9592\n",
            "Epoch 40/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2008 - accuracy: 0.9416 - val_loss: 0.1389 - val_accuracy: 0.9596\n",
            "Epoch 41/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2002 - accuracy: 0.9413 - val_loss: 0.1370 - val_accuracy: 0.9598\n",
            "Epoch 42/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1982 - accuracy: 0.9416 - val_loss: 0.1357 - val_accuracy: 0.9603\n",
            "Epoch 43/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1994 - accuracy: 0.9409 - val_loss: 0.1342 - val_accuracy: 0.9611\n",
            "Epoch 44/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1911 - accuracy: 0.9442 - val_loss: 0.1330 - val_accuracy: 0.9609\n",
            "Epoch 45/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1903 - accuracy: 0.9444 - val_loss: 0.1307 - val_accuracy: 0.9613\n",
            "Epoch 46/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1891 - accuracy: 0.9443 - val_loss: 0.1293 - val_accuracy: 0.9613\n",
            "Epoch 47/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1874 - accuracy: 0.9443 - val_loss: 0.1291 - val_accuracy: 0.9619\n",
            "Epoch 48/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1838 - accuracy: 0.9464 - val_loss: 0.1272 - val_accuracy: 0.9626\n",
            "Epoch 49/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1818 - accuracy: 0.9460 - val_loss: 0.1262 - val_accuracy: 0.9625\n",
            "Epoch 50/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1828 - accuracy: 0.9470 - val_loss: 0.1256 - val_accuracy: 0.9625\n",
            "Epoch 51/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1781 - accuracy: 0.9480 - val_loss: 0.1241 - val_accuracy: 0.9628\n",
            "Epoch 52/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1754 - accuracy: 0.9488 - val_loss: 0.1225 - val_accuracy: 0.9637\n",
            "Epoch 53/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1728 - accuracy: 0.9478 - val_loss: 0.1217 - val_accuracy: 0.9629\n",
            "Epoch 54/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1759 - accuracy: 0.9476 - val_loss: 0.1206 - val_accuracy: 0.9636\n",
            "Epoch 55/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1713 - accuracy: 0.9496 - val_loss: 0.1194 - val_accuracy: 0.9638\n",
            "Epoch 56/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1698 - accuracy: 0.9501 - val_loss: 0.1182 - val_accuracy: 0.9645\n",
            "Epoch 57/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1715 - accuracy: 0.9491 - val_loss: 0.1173 - val_accuracy: 0.9651\n",
            "Epoch 58/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1649 - accuracy: 0.9517 - val_loss: 0.1169 - val_accuracy: 0.9658\n",
            "Epoch 59/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1636 - accuracy: 0.9517 - val_loss: 0.1162 - val_accuracy: 0.9646\n",
            "Epoch 60/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1639 - accuracy: 0.9507 - val_loss: 0.1154 - val_accuracy: 0.9656\n",
            "Epoch 61/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1619 - accuracy: 0.9516 - val_loss: 0.1145 - val_accuracy: 0.9653\n",
            "Epoch 62/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1598 - accuracy: 0.9540 - val_loss: 0.1140 - val_accuracy: 0.9663\n",
            "Epoch 63/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1570 - accuracy: 0.9535 - val_loss: 0.1134 - val_accuracy: 0.9661\n",
            "Epoch 64/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1565 - accuracy: 0.9542 - val_loss: 0.1122 - val_accuracy: 0.9665\n",
            "Epoch 65/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1565 - accuracy: 0.9543 - val_loss: 0.1107 - val_accuracy: 0.9676\n",
            "Epoch 66/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1550 - accuracy: 0.9540 - val_loss: 0.1108 - val_accuracy: 0.9672\n",
            "Epoch 67/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1533 - accuracy: 0.9547 - val_loss: 0.1101 - val_accuracy: 0.9678\n",
            "Epoch 68/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1494 - accuracy: 0.9566 - val_loss: 0.1096 - val_accuracy: 0.9687\n",
            "Epoch 69/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1502 - accuracy: 0.9548 - val_loss: 0.1088 - val_accuracy: 0.9682\n",
            "Epoch 70/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1501 - accuracy: 0.9564 - val_loss: 0.1080 - val_accuracy: 0.9688\n",
            "Epoch 71/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1464 - accuracy: 0.9570 - val_loss: 0.1076 - val_accuracy: 0.9684\n",
            "Epoch 72/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1465 - accuracy: 0.9561 - val_loss: 0.1070 - val_accuracy: 0.9686\n",
            "Epoch 73/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1456 - accuracy: 0.9569 - val_loss: 0.1068 - val_accuracy: 0.9688\n",
            "Epoch 74/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1436 - accuracy: 0.9573 - val_loss: 0.1056 - val_accuracy: 0.9692\n",
            "Epoch 75/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1421 - accuracy: 0.9586 - val_loss: 0.1055 - val_accuracy: 0.9692\n",
            "Epoch 76/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1405 - accuracy: 0.9589 - val_loss: 0.1046 - val_accuracy: 0.9694\n",
            "Epoch 77/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1395 - accuracy: 0.9592 - val_loss: 0.1049 - val_accuracy: 0.9694\n",
            "Epoch 78/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1398 - accuracy: 0.9589 - val_loss: 0.1037 - val_accuracy: 0.9699\n",
            "Epoch 79/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1379 - accuracy: 0.9590 - val_loss: 0.1035 - val_accuracy: 0.9693\n",
            "Epoch 80/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1353 - accuracy: 0.9602 - val_loss: 0.1035 - val_accuracy: 0.9702\n",
            "Epoch 81/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1358 - accuracy: 0.9596 - val_loss: 0.1028 - val_accuracy: 0.9693\n",
            "Epoch 82/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1343 - accuracy: 0.9603 - val_loss: 0.1018 - val_accuracy: 0.9697\n",
            "Epoch 83/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1342 - accuracy: 0.9608 - val_loss: 0.1019 - val_accuracy: 0.9700\n",
            "Epoch 84/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1340 - accuracy: 0.9595 - val_loss: 0.1010 - val_accuracy: 0.9706\n",
            "Epoch 85/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1313 - accuracy: 0.9603 - val_loss: 0.1011 - val_accuracy: 0.9697\n",
            "Epoch 86/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1325 - accuracy: 0.9604 - val_loss: 0.1009 - val_accuracy: 0.9707\n",
            "Epoch 87/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1288 - accuracy: 0.9626 - val_loss: 0.0992 - val_accuracy: 0.9708\n",
            "Epoch 88/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1303 - accuracy: 0.9608 - val_loss: 0.0999 - val_accuracy: 0.9707\n",
            "Epoch 89/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1283 - accuracy: 0.9613 - val_loss: 0.0995 - val_accuracy: 0.9705\n",
            "Epoch 90/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1277 - accuracy: 0.9616 - val_loss: 0.0991 - val_accuracy: 0.9712\n",
            "Epoch 91/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1252 - accuracy: 0.9620 - val_loss: 0.0993 - val_accuracy: 0.9704\n",
            "Epoch 92/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1286 - accuracy: 0.9617 - val_loss: 0.0979 - val_accuracy: 0.9709\n",
            "Epoch 93/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1257 - accuracy: 0.9624 - val_loss: 0.0983 - val_accuracy: 0.9707\n",
            "Epoch 94/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1264 - accuracy: 0.9616 - val_loss: 0.0977 - val_accuracy: 0.9709\n",
            "Epoch 95/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1211 - accuracy: 0.9628 - val_loss: 0.0976 - val_accuracy: 0.9708\n",
            "Epoch 96/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1235 - accuracy: 0.9629 - val_loss: 0.0975 - val_accuracy: 0.9713\n",
            "Epoch 97/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1229 - accuracy: 0.9631 - val_loss: 0.0971 - val_accuracy: 0.9718\n",
            "Epoch 98/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1211 - accuracy: 0.9638 - val_loss: 0.0963 - val_accuracy: 0.9713\n",
            "Epoch 99/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1200 - accuracy: 0.9647 - val_loss: 0.0966 - val_accuracy: 0.9714\n",
            "Epoch 100/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1186 - accuracy: 0.9641 - val_loss: 0.0953 - val_accuracy: 0.9716\n",
            "Epoch 101/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1206 - accuracy: 0.9636 - val_loss: 0.0950 - val_accuracy: 0.9715\n",
            "Epoch 102/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1162 - accuracy: 0.9647 - val_loss: 0.0950 - val_accuracy: 0.9718\n",
            "Epoch 103/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1191 - accuracy: 0.9649 - val_loss: 0.0942 - val_accuracy: 0.9718\n",
            "Epoch 104/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1156 - accuracy: 0.9654 - val_loss: 0.0948 - val_accuracy: 0.9725\n",
            "Epoch 105/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1152 - accuracy: 0.9653 - val_loss: 0.0942 - val_accuracy: 0.9721\n",
            "Epoch 106/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1152 - accuracy: 0.9646 - val_loss: 0.0943 - val_accuracy: 0.9718\n",
            "Epoch 107/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1145 - accuracy: 0.9663 - val_loss: 0.0944 - val_accuracy: 0.9720\n",
            "Epoch 108/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1142 - accuracy: 0.9663 - val_loss: 0.0937 - val_accuracy: 0.9728\n",
            "Epoch 109/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1150 - accuracy: 0.9652 - val_loss: 0.0925 - val_accuracy: 0.9727\n",
            "Epoch 110/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1138 - accuracy: 0.9655 - val_loss: 0.0932 - val_accuracy: 0.9725\n",
            "Epoch 111/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1116 - accuracy: 0.9662 - val_loss: 0.0924 - val_accuracy: 0.9728\n",
            "Epoch 112/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1112 - accuracy: 0.9673 - val_loss: 0.0925 - val_accuracy: 0.9725\n",
            "Epoch 113/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1100 - accuracy: 0.9675 - val_loss: 0.0920 - val_accuracy: 0.9727\n",
            "Epoch 114/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1069 - accuracy: 0.9672 - val_loss: 0.0919 - val_accuracy: 0.9728\n",
            "Epoch 115/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1078 - accuracy: 0.9682 - val_loss: 0.0926 - val_accuracy: 0.9725\n",
            "Epoch 116/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1087 - accuracy: 0.9673 - val_loss: 0.0923 - val_accuracy: 0.9725\n",
            "Epoch 117/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1082 - accuracy: 0.9688 - val_loss: 0.0916 - val_accuracy: 0.9727\n",
            "Epoch 118/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1070 - accuracy: 0.9676 - val_loss: 0.0912 - val_accuracy: 0.9729\n",
            "Epoch 119/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1046 - accuracy: 0.9688 - val_loss: 0.0915 - val_accuracy: 0.9731\n",
            "Epoch 120/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1092 - accuracy: 0.9666 - val_loss: 0.0909 - val_accuracy: 0.9730\n",
            "Epoch 121/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1060 - accuracy: 0.9684 - val_loss: 0.0905 - val_accuracy: 0.9731\n",
            "Epoch 122/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1050 - accuracy: 0.9681 - val_loss: 0.0906 - val_accuracy: 0.9734\n",
            "Epoch 123/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1032 - accuracy: 0.9686 - val_loss: 0.0901 - val_accuracy: 0.9734\n",
            "Epoch 124/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1032 - accuracy: 0.9697 - val_loss: 0.0899 - val_accuracy: 0.9734\n",
            "Epoch 125/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1033 - accuracy: 0.9682 - val_loss: 0.0901 - val_accuracy: 0.9732\n",
            "Epoch 126/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1054 - accuracy: 0.9675 - val_loss: 0.0898 - val_accuracy: 0.9732\n",
            "Epoch 127/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1031 - accuracy: 0.9686 - val_loss: 0.0890 - val_accuracy: 0.9736\n",
            "Epoch 128/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1020 - accuracy: 0.9690 - val_loss: 0.0896 - val_accuracy: 0.9736\n",
            "Epoch 129/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1019 - accuracy: 0.9687 - val_loss: 0.0896 - val_accuracy: 0.9733\n",
            "Epoch 130/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0990 - accuracy: 0.9689 - val_loss: 0.0888 - val_accuracy: 0.9737\n",
            "Epoch 131/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1014 - accuracy: 0.9690 - val_loss: 0.0886 - val_accuracy: 0.9730\n",
            "Epoch 132/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1021 - accuracy: 0.9699 - val_loss: 0.0882 - val_accuracy: 0.9732\n",
            "Epoch 133/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0988 - accuracy: 0.9703 - val_loss: 0.0889 - val_accuracy: 0.9732\n",
            "Epoch 134/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0984 - accuracy: 0.9700 - val_loss: 0.0880 - val_accuracy: 0.9736\n",
            "Epoch 135/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0998 - accuracy: 0.9693 - val_loss: 0.0880 - val_accuracy: 0.9735\n",
            "Epoch 136/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0942 - accuracy: 0.9719 - val_loss: 0.0884 - val_accuracy: 0.9732\n",
            "Epoch 137/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0963 - accuracy: 0.9709 - val_loss: 0.0880 - val_accuracy: 0.9737\n",
            "Epoch 138/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0949 - accuracy: 0.9711 - val_loss: 0.0876 - val_accuracy: 0.9734\n",
            "Epoch 139/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0950 - accuracy: 0.9711 - val_loss: 0.0882 - val_accuracy: 0.9732\n",
            "Epoch 140/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0953 - accuracy: 0.9712 - val_loss: 0.0882 - val_accuracy: 0.9732\n",
            "Epoch 141/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0993 - accuracy: 0.9700 - val_loss: 0.0879 - val_accuracy: 0.9733\n",
            "Epoch 142/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0941 - accuracy: 0.9713 - val_loss: 0.0870 - val_accuracy: 0.9743\n",
            "Epoch 143/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0949 - accuracy: 0.9706 - val_loss: 0.0871 - val_accuracy: 0.9738\n",
            "Epoch 144/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0944 - accuracy: 0.9704 - val_loss: 0.0870 - val_accuracy: 0.9742\n",
            "Epoch 145/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0953 - accuracy: 0.9709 - val_loss: 0.0869 - val_accuracy: 0.9737\n",
            "Epoch 146/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0929 - accuracy: 0.9719 - val_loss: 0.0866 - val_accuracy: 0.9737\n",
            "Epoch 147/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0922 - accuracy: 0.9723 - val_loss: 0.0867 - val_accuracy: 0.9743\n",
            "Epoch 148/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0910 - accuracy: 0.9720 - val_loss: 0.0868 - val_accuracy: 0.9740\n",
            "Epoch 149/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0906 - accuracy: 0.9724 - val_loss: 0.0867 - val_accuracy: 0.9745\n",
            "Epoch 150/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0913 - accuracy: 0.9714 - val_loss: 0.0865 - val_accuracy: 0.9742\n",
            "Epoch 151/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0890 - accuracy: 0.9734 - val_loss: 0.0863 - val_accuracy: 0.9742\n",
            "Epoch 152/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0895 - accuracy: 0.9728 - val_loss: 0.0859 - val_accuracy: 0.9749\n",
            "Epoch 153/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0908 - accuracy: 0.9715 - val_loss: 0.0860 - val_accuracy: 0.9747\n",
            "Epoch 154/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0906 - accuracy: 0.9717 - val_loss: 0.0860 - val_accuracy: 0.9743\n",
            "Epoch 155/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0898 - accuracy: 0.9722 - val_loss: 0.0861 - val_accuracy: 0.9746\n",
            "Epoch 156/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0880 - accuracy: 0.9732 - val_loss: 0.0865 - val_accuracy: 0.9747\n",
            "Epoch 157/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0877 - accuracy: 0.9722 - val_loss: 0.0860 - val_accuracy: 0.9748\n",
            "Epoch 158/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0876 - accuracy: 0.9728 - val_loss: 0.0856 - val_accuracy: 0.9752\n",
            "Epoch 159/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0894 - accuracy: 0.9725 - val_loss: 0.0855 - val_accuracy: 0.9747\n",
            "Epoch 160/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0877 - accuracy: 0.9731 - val_loss: 0.0852 - val_accuracy: 0.9750\n",
            "Epoch 161/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0879 - accuracy: 0.9724 - val_loss: 0.0854 - val_accuracy: 0.9750\n",
            "Epoch 162/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0852 - accuracy: 0.9739 - val_loss: 0.0856 - val_accuracy: 0.9749\n",
            "Epoch 163/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0856 - accuracy: 0.9737 - val_loss: 0.0854 - val_accuracy: 0.9747\n",
            "Epoch 164/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0873 - accuracy: 0.9736 - val_loss: 0.0855 - val_accuracy: 0.9747\n",
            "Epoch 165/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0839 - accuracy: 0.9729 - val_loss: 0.0855 - val_accuracy: 0.9748\n",
            "Epoch 166/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0840 - accuracy: 0.9747 - val_loss: 0.0848 - val_accuracy: 0.9747\n",
            "Epoch 167/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0850 - accuracy: 0.9732 - val_loss: 0.0846 - val_accuracy: 0.9749\n",
            "Epoch 168/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0840 - accuracy: 0.9744 - val_loss: 0.0846 - val_accuracy: 0.9750\n",
            "Epoch 169/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0841 - accuracy: 0.9745 - val_loss: 0.0851 - val_accuracy: 0.9754\n",
            "Epoch 170/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0830 - accuracy: 0.9739 - val_loss: 0.0848 - val_accuracy: 0.9759\n",
            "Epoch 171/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0839 - accuracy: 0.9736 - val_loss: 0.0846 - val_accuracy: 0.9747\n",
            "Epoch 172/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0830 - accuracy: 0.9744 - val_loss: 0.0840 - val_accuracy: 0.9753\n",
            "Epoch 173/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0823 - accuracy: 0.9739 - val_loss: 0.0841 - val_accuracy: 0.9761\n",
            "Epoch 174/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0804 - accuracy: 0.9753 - val_loss: 0.0845 - val_accuracy: 0.9754\n",
            "Epoch 175/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0818 - accuracy: 0.9748 - val_loss: 0.0853 - val_accuracy: 0.9753\n",
            "Epoch 176/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0803 - accuracy: 0.9753 - val_loss: 0.0847 - val_accuracy: 0.9753\n",
            "Epoch 177/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0803 - accuracy: 0.9750 - val_loss: 0.0843 - val_accuracy: 0.9746\n",
            "Epoch 178/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0800 - accuracy: 0.9750 - val_loss: 0.0837 - val_accuracy: 0.9755\n",
            "Epoch 179/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0804 - accuracy: 0.9745 - val_loss: 0.0847 - val_accuracy: 0.9750\n",
            "Epoch 180/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0801 - accuracy: 0.9750 - val_loss: 0.0842 - val_accuracy: 0.9753\n",
            "Epoch 181/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0796 - accuracy: 0.9752 - val_loss: 0.0847 - val_accuracy: 0.9748\n",
            "Epoch 182/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0789 - accuracy: 0.9748 - val_loss: 0.0836 - val_accuracy: 0.9751\n",
            "Epoch 183/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0790 - accuracy: 0.9759 - val_loss: 0.0833 - val_accuracy: 0.9755\n",
            "Epoch 184/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0802 - accuracy: 0.9745 - val_loss: 0.0829 - val_accuracy: 0.9755\n",
            "Epoch 185/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0780 - accuracy: 0.9755 - val_loss: 0.0830 - val_accuracy: 0.9762\n",
            "Epoch 186/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0763 - accuracy: 0.9762 - val_loss: 0.0836 - val_accuracy: 0.9760\n",
            "Epoch 187/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0785 - accuracy: 0.9754 - val_loss: 0.0832 - val_accuracy: 0.9759\n",
            "Epoch 188/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0776 - accuracy: 0.9759 - val_loss: 0.0838 - val_accuracy: 0.9754\n",
            "Epoch 189/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0766 - accuracy: 0.9770 - val_loss: 0.0835 - val_accuracy: 0.9757\n",
            "Epoch 190/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0779 - accuracy: 0.9756 - val_loss: 0.0839 - val_accuracy: 0.9759\n",
            "Epoch 191/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0751 - accuracy: 0.9763 - val_loss: 0.0841 - val_accuracy: 0.9751\n",
            "Epoch 192/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0762 - accuracy: 0.9771 - val_loss: 0.0839 - val_accuracy: 0.9754\n",
            "Epoch 193/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0752 - accuracy: 0.9765 - val_loss: 0.0827 - val_accuracy: 0.9762\n",
            "Epoch 194/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0765 - accuracy: 0.9756 - val_loss: 0.0824 - val_accuracy: 0.9764\n",
            "Epoch 195/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0739 - accuracy: 0.9775 - val_loss: 0.0829 - val_accuracy: 0.9760\n",
            "Epoch 196/200\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0779 - accuracy: 0.9761 - val_loss: 0.0828 - val_accuracy: 0.9760\n",
            "Epoch 197/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0753 - accuracy: 0.9765 - val_loss: 0.0831 - val_accuracy: 0.9759\n",
            "Epoch 198/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0748 - accuracy: 0.9766 - val_loss: 0.0826 - val_accuracy: 0.9763\n",
            "Epoch 199/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0775 - accuracy: 0.9762 - val_loss: 0.0823 - val_accuracy: 0.9762\n",
            "Epoch 200/200\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0751 - accuracy: 0.9769 - val_loss: 0.0822 - val_accuracy: 0.9762\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1e50164a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWvijvET3K11",
        "colab_type": "code",
        "outputId": "f0ace893-2fda-4a0a-bb11-f416cdfa08c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy: ', test_acc)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.0730 - accuracy: 0.9778\n",
            "Test accuracy:  0.9778000116348267\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQy2lsAf3sFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}